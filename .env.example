# Variables de entorno para CODI Core FASE 2: Integración con LLMs

# Clave de API de OpenAI (o compatible)
OPENAI_API_KEY=tu_clave_aqui

# Modelo de LLM a utilizar (ej: gpt-4-turbo, gemini-2.5-flash)
OPENAI_MODEL=gpt-4-turbo

# Tiempo máximo de espera para la respuesta del LLM (en segundos)
LLM_TIMEOUT=30

# Número máximo de reintentos en caso de fallo del LLM
LLM_MAX_RETRIES=3
